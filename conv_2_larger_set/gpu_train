#!/bin/bash
# Job name:
#SBATCH --job-name=Model_train
#
# Partition - This is the queue it goes in:
#SBATCH --partition=main
#
#
# Number of nodes you need per job:
#SBATCH --nodes=1
#SBATCH --nodelist=phoenix-02
#
# Memory needed for the jobs.  Try very hard to make this accurate.  DEFAULT = 4gb
#SBATCH --mem=500gb
#
# Number of tasks (one for each CPU desired for use case) (example):
#SBATCH --ntasks=1
#
# Processors per task:
# At least eight times the number of GPUs needed for nVidia RTX A5500
#SBATCH --cpus-per-task=64
#
# Number of GPUs, this can be in the format of "--gres=gpu:[1-8]", or "--gres=gpu:A5500:[1-8]" with the type included (optional)
#SBATCH --gres=gpu:8
#
# Standard output and error log
#SBATCH --output=log_new
#
# Wall clock limit in hrs:min:sec:
#SBATCH --time=10:00:00

python3 train.py
